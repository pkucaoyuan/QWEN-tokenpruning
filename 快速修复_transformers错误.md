# å¿«é€Ÿä¿®å¤ï¼štransformers å…¼å®¹æ€§é”™è¯¯

## âŒ å¸¸è§é”™è¯¯

### é”™è¯¯1ï¼štransformers å…¼å®¹æ€§

```
AttributeError: 'dict' object has no attribute 'to_dict'
```

å‘ç”Ÿåœ¨åŠ è½½ Qwen2.5-VL text_encoder æ—¶ã€‚

### é”™è¯¯2ï¼šPEFT backend ç¼ºå¤±

```
ValueError: PEFT backend is required for this method.
```

å‘ç”Ÿåœ¨åŠ è½½ LoRA æƒé‡æ—¶ã€‚

---

## âœ… è§£å†³æ–¹æ¡ˆ

### **æ–¹æ³•1ï¼šè‡ªåŠ¨ä¿®å¤ï¼ˆæ¨èï¼‰â­**

è¿è¡Œç¯å¢ƒæ£€æŸ¥å’Œä¿®å¤è„šæœ¬ï¼š

```bash
python 0_ç¯å¢ƒæ£€æŸ¥å’Œä¿®å¤.py
```

æ­¤è„šæœ¬ä¼šï¼š
- âœ… è‡ªåŠ¨æ£€æŸ¥æ‰€æœ‰ä¾èµ–
- âœ… è‡ªåŠ¨å‡çº§ transformers åˆ° 4.48.0+
- âœ… **è‡ªåŠ¨å®‰è£… peft åº“**
- âœ… è‡ªåŠ¨ä¿®å¤ç¯å¢ƒé—®é¢˜
- âœ… è‡ªåŠ¨è½¬æ¢å›¾ç‰‡æ ¼å¼

---

### **æ–¹æ³•2ï¼šæ‰‹åŠ¨ä¿®å¤ï¼ˆå¿«é€Ÿï¼‰**

```bash
# å®‰è£…ç¼ºå¤±çš„ä¾èµ–
pip install --upgrade transformers>=4.48.0
pip install peft>=0.13.0

# é‡æ–°è¿è¡Œ
python 2_load_and_inference_lightning.py
```

---

### **æ–¹æ³•3ï¼šä½¿ç”¨ä¿®å¤è„šæœ¬**

```bash
python fix_transformers_error.py
```

---

## ğŸ”§ å®Œæ•´ä¿®å¤æµç¨‹

```bash
# 1. å‡çº§ transformers
pip install --upgrade transformers>=4.48.0

# 2. éªŒè¯ç‰ˆæœ¬
python -c "import transformers; print(transformers.__version__)"
# åº”è¯¥æ˜¾ç¤º 4.48.0 æˆ–æ›´é«˜

# 3. é‡æ–°è¿è¡Œæ¨ç†
python 2_load_and_inference_lightning.py
```

---

## ğŸ“‹ æ¨èçš„ä¾èµ–ç‰ˆæœ¬

```
torch>=2.0.0
transformers>=4.48.0  â­ å…³é”®
diffusers>=0.36.0
accelerate>=0.20.0
pillow>=9.0.0
safetensors>=0.3.0
huggingface_hub>=0.20.0
peft>=0.13.0  â­ LoRA åŠ è½½å¿…éœ€
```

---

## ğŸš€ ä»å¤´å¼€å§‹ï¼ˆå®Œæ•´æµç¨‹ï¼‰

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/pkucaoyuan/QWEN-tokenpruning.git
cd QWEN-tokenpruning

# 2. è¿è¡Œç¯å¢ƒæ£€æŸ¥ï¼ˆè‡ªåŠ¨ä¿®å¤ï¼‰â­ æ¨è
python 0_ç¯å¢ƒæ£€æŸ¥å’Œä¿®å¤.py

# 3. è¿è¡Œæ¨ç†
python 2_load_and_inference_lightning.py
```

---

## ğŸ› å¦‚æœä»ç„¶å‡ºé”™

### é”™è¯¯1ï¼štransformers ç‰ˆæœ¬ä»ç„¶è¿‡ä½

```bash
# å¼ºåˆ¶é‡è£…æœ€æ–°ç‰ˆ
pip uninstall transformers -y
pip install transformers>=4.48.0
```

### é”™è¯¯2ï¼šCUDA ä¸å¯ç”¨

```bash
# æ£€æŸ¥ CUDA
python -c "import torch; print(torch.cuda.is_available())"

# å¦‚æœä¸º Falseï¼Œæ£€æŸ¥ PyTorch å®‰è£…
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

### é”™è¯¯3ï¼šæ˜¾å­˜ä¸è¶³

åœ¨è„šæœ¬ä¸­æ·»åŠ ï¼š
```python
# åœ¨ pipe.to("cuda") ä¹‹åæ·»åŠ 
pipe.enable_model_cpu_offload()  # CPU offload
pipe.vae.enable_tiling()         # VAE tiling
```

---

## âœ… éªŒè¯ä¿®å¤æˆåŠŸ

```bash
# æ£€æŸ¥ transformers ç‰ˆæœ¬
python -c "import transformers; print(f'transformers: {transformers.__version__}')"

# åº”è¯¥æ˜¾ç¤º: transformers: 4.48.0 æˆ–æ›´é«˜
```

---

## ğŸ“ å¦‚æœé—®é¢˜æŒç»­

1. æ£€æŸ¥ Python ç‰ˆæœ¬ï¼š`python --version`ï¼ˆéœ€è¦ 3.8+ï¼‰
2. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒï¼šç¡®ä¿åœ¨æ­£ç¡®çš„ç¯å¢ƒä¸­
3. æ¸…ç†ç¼“å­˜ï¼š`pip cache purge`
4. é‡æ–°å®‰è£…ä¾èµ–ï¼š`pip install -r requirements.txt --upgrade`

